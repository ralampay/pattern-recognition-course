{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd0f045",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianNB\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to the location of your wbpc.data file\n",
    "file_raw_data = \"/home/ralampay/workspace/pattern-recognition-course/data/wdbc.csv\"\n",
    "\n",
    "raw_data = pd.read_csv(file_raw_data, header=None)\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = raw_data.iloc[:,2:32]\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21915615",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(x.columns)\n",
    "\n",
    "print(\"Number of Features: {}\".format(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "\n",
    "for i in range(num_features):\n",
    "    columns.append(\"x{}\".format(i))\n",
    "\n",
    "x.columns = columns\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x.mean()\n",
    "x_std = x.std()\n",
    "x_standardized = (x - x_mean)/x_std\n",
    "\n",
    "x_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad183db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normalized = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33359c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw_data[1].replace(['B'], 0).replace(['M'], 1)\n",
    "\n",
    "y = y.values\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_benign = len(raw_data[raw_data.iloc[:,1] == 'B'])\n",
    "num_malignant = len(raw_data[raw_data.iloc[:,1] == 'M'])\n",
    "\n",
    "print(\"num_benign: {}\".format(num_benign))\n",
    "print(\"num_malignant: {}\".format(num_malignant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ff51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_normalized.copy()\n",
    "df['y'] = y\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7ec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(df, num_a=20, num_b=20, val_a=1, val_b=0):\n",
    "    df_a = df[df.iloc[:,-1] == val_a].sample(num_a)\n",
    "    df_b = df[df.iloc[:,-1] == val_b].sample(num_b)\n",
    "    \n",
    "    df.drop(df_a.index, inplace=True)\n",
    "    df.drop(df_b.index, inplace=True)\n",
    "    \n",
    "    frames = [df_a, df_b]\n",
    "    df_validation = pd.concat(frames)\n",
    "    \n",
    "    return df, df_validation\n",
    "\n",
    "training, validation = partition_dataset(df, num_a=20, num_b=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f35aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96767b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training = training.iloc[:,:-1].values\n",
    "x_validation = validation.iloc[:,:-1].values\n",
    "\n",
    "y_training = training['y'].values\n",
    "y_validation = validation['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffeffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_1 = nn.Linear(input_dim, 25)\n",
    "        self.input_2 = nn.Linear(25, 20)\n",
    "        self.input_3 = nn.Linear(20, 10)\n",
    "        self.output = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # f(x) = a(f(x))\n",
    "        x = F.relu(self.input_1(x))\n",
    "        x = F.relu(self.input_2(x))\n",
    "        x = F.relu(self.input_3(x))\n",
    "        y = F.sigmoid(self.output(x))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd7944",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(x_training)\n",
    "model = MultiLayerPerceptron(30, 1)\n",
    "\n",
    "y = model.forward(x)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad3ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973fe178",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30265b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.n_samples = len(x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37812c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x_training).float().to(device)\n",
    "y = torch.tensor(y_training).float().to(device)\n",
    "\n",
    "training_ds = CustomDataset(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273be1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e46ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, device):\n",
    "    loop = tqdm(loader)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    train_fn(train_loader, model, optimizer, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.forward(torch.tensor([x_validation]).float()).cpu().detach().numpy()\n",
    "\n",
    "predictions = predictions.ravel()\n",
    "\n",
    "predictions = [1 if y >= 0.5 else 0 for y in predictions]\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e92dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_validation, predictions)\n",
    "tp = cm[0][0]\n",
    "tn = cm[1][1]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "\n",
    "mcc = ((tn * tp) - (fn * fp)) / math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "f1 = tp / (tp + (0.5 * (fp + fn)))\n",
    "\n",
    "print(classification_report(y_validation, predictions))\n",
    "print(\"MCC: {}\".format(mcc))\n",
    "print(\"F1: {}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9dec3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

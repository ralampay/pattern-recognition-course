{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894fb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://debuggercafe.com/getting-started-with-variational-autoencoder-using-pytorch/\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, num_features=8, num_dim=784):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.num_dim = num_dim\n",
    "        \n",
    "        self.encoder_layer_1 = nn.Linear(in_features=self.num_dim, out_features=512)\n",
    "        self.encoder_layer_2 = nn.Linear(in_features=512, out_features=(self.num_features * 2))\n",
    "        \n",
    "        self.decoder_layer_1 = nn.Linear(in_features=self.num_features, out_features=512)\n",
    "        self.decoder_layer_2 = nn.Linear(in_features=512, out_features=self.num_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std)  # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std)    # sampling as if coming from the input space\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.encoder_layer_1(x))\n",
    "        x = self.encoder_layer_2(x).view(-1, 2, self.num_features)\n",
    "        \n",
    "        # get `mu` and `log_var`\n",
    "        mu = x[:, 0, :] # the first feature values as mean\n",
    "        log_var = x[:, 1, :] # the other feature values as variance\n",
    "        \n",
    "        print(mu.shape)\n",
    "        print(log_var.shape)\n",
    "        \n",
    "        print(mu)\n",
    "        \n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    " \n",
    "        # decoding\n",
    "        x = F.relu(self.decoder_layer_1(z))\n",
    "        reconstruction = torch.sigmoid(self.decoder_layer_2(x))\n",
    "        \n",
    "        return reconstruction, mu, log_var\n",
    "    \n",
    "    def sample(self, mu, log_var):\n",
    "        # get the latent vector through reparameterization\n",
    "        z = self.reparameterize(mu, log_var)\n",
    " \n",
    "        # decoding\n",
    "        x = F.relu(self.decoder_layer_1(z))\n",
    "        reconstruction = torch.sigmoid(self.decoder_layer_2(x))\n",
    "        \n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderDataset(Dataset):         \n",
    "    def __init__(self, x):    \n",
    "        self.x = x\n",
    "\n",
    "        self.n_samples = len(x)\n",
    "                                                                  \n",
    "    def __getitem__(self, index):                   \n",
    "        return self.x[index], self.x[index]                \n",
    "                                                     \n",
    "    def __len__(self):                                                                                   \n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "dim = (img_width, img_height)\n",
    "\n",
    "doggos = [\n",
    "    \"./images/labrador1.jpg\",\n",
    "    \"./images/labrador2.jpg\",\n",
    "    \"./images/labrador3.jpg\",\n",
    "    \"./images/labrador4.jpg\",\n",
    "    \"./images/labrador5.jpg\"\n",
    "]\n",
    "\n",
    "images = []\n",
    "\n",
    "for doggo in doggos:\n",
    "    img = cv2.imread(doggo, 0) / 255 # read as grayscale 1 channel images and normalize\n",
    "    \n",
    "    img = cv2.resize(img, dim)\n",
    "    \n",
    "    images.append(img)\n",
    "\n",
    "num_images = len(images)\n",
    "num_cols   = 1\n",
    "\n",
    "col_names = [\n",
    "    \"Original\"\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_images, ncols=num_cols, figsize=(num_cols*4, num_images*4))\n",
    "counter = 0\n",
    "\n",
    "for img in images:\n",
    "    counter += 1\n",
    "    \n",
    "    plt.subplot(len(images), num_cols, counter)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for img in images:\n",
    "    data.append(img.ravel())\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(np.array(data))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "num_features=8\n",
    "\n",
    "model = VariationalAutoencoder(num_features=num_features).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2afd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_loss(bce_loss, mu, logvar):\n",
    "    \"\"\"\n",
    "    This function will add the reconstruction loss (BCELoss) and the \n",
    "    KL-Divergence.\n",
    "    KL-Divergence = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    :param bce_loss: recontruction loss\n",
    "    :param mu: the mean from the latent vector\n",
    "    :param logvar: log variance from the latent vector\n",
    "    \"\"\"\n",
    "    BCE = bce_loss \n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1091ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = AutoencoderDataset(\n",
    "    x=x\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    ave_loss = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data    = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        reconstruction, mu, logvar = model.forward(data)\n",
    "        \n",
    "        bce_loss = criterion(reconstruction, data)\n",
    "        \n",
    "        loss = final_loss(bce_loss, mu, logvar)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        ave_loss += loss.item()\n",
    "        count += 1\n",
    "\n",
    "    ave_loss = ave_loss / count\n",
    "\n",
    "    return ave_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60664e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    ave_loss = train_fn(train_loader, model, optimizer, final_loss)\n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "\n",
    "    state = {\n",
    "        'state_dict':       model.state_dict(),\n",
    "        'optimizer':        optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    torch.save(state, \"autoencoder.pth\")\n",
    "    \n",
    "    losses.append(ave_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73cea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_mu = torch.Tensor([np.zeros(num_features)])\n",
    "sampled_logvar = torch.Tensor([np.zeros(num_features)])\n",
    "\n",
    "sampled_mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = model.sample(sampled_mu, sampled_logvar)\n",
    "\n",
    "reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image = reconstruction[0].detach().cpu().numpy()\n",
    "reconstructed_image = reconstructed_image.reshape(img_width, img_height)\n",
    "plt.imshow(reconstructed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11a5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

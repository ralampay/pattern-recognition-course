{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"phoneprices.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "\n",
    "x_normalized = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df.iloc[:,-1], prefix='y')\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_normalized, y, test_size=0.3)\n",
    "\n",
    "len_input = len(x_train.columns)\n",
    "len_output = len(y_train.columns)\n",
    "\n",
    "print(\"Len Input: {}\".format(len_input))\n",
    "print(\"Len Output: {}\".format(len_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        self.n_samples = len(x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(nd_array):\n",
    "    one_hot_encoding_predictions = nd_array\n",
    "\n",
    "    for i in range(len(nd_array)):\n",
    "        max_pred = max(nd_array[i])\n",
    "\n",
    "        for j in range(len(nd_array[i])):\n",
    "            one_hot_encoding_predictions[i][j] = 1 if nd_array[i][j] == max_pred else 0\n",
    "\n",
    "    return one_hot_encoding_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_1 = nn.Linear(input_dim, 10)\n",
    "        self.output = nn.Linear(10, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # f(x) = a(f(x))\n",
    "        x = F.relu(self.input_1(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        y = F.softmax(x, dim=-1)\n",
    "\n",
    "        return y\n",
    "\n",
    "model = MultiLayerPerceptron(len_input, len_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(loader, model, optimizer, loss_fn, device):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    average_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "        \n",
    "        predictions = F.softmax(predictions, dim=-1)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update tqdm\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        average_loss += loss.item()\n",
    "        count += 1\n",
    "    \n",
    "    average_loss = average_loss / count\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "device = 'cpu'\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train.values).float().to(device)\n",
    "y_train = torch.tensor(y_train.values).float().to(device)\n",
    "\n",
    "x_test = torch.tensor(x_test.values).float().to(device)\n",
    "y_test = torch.tensor(y_test.values).float().to(device)\n",
    "\n",
    "training_ds = CustomDataset(x_train, y_train)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    training_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y_test to numpy array\n",
    "y_test = y_test.detach().cpu().numpy()\n",
    "\n",
    "# Array to store the losses\n",
    "losses = []\n",
    "\n",
    "# Array to store accuracy score\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    average_loss = train_fn(train_loader, model, optimizer, criterion, device)\n",
    "\n",
    "    # Perform a prediction at every epoch\n",
    "    one_hot_encoding_predictions = one_hot_encoding(\n",
    "        model.forward(x_test).detach().cpu().numpy()\n",
    "    )\n",
    "\n",
    "    print(one_hot_encoding)\n",
    "\n",
    "    # Get the accuracy at every epoch\n",
    "    acc_score = accuracy_score(\n",
    "        y_test,\n",
    "        one_hot_encoding_predictions\n",
    "    )\n",
    "\n",
    "    losses.append(average_loss)\n",
    "\n",
    "    accuracies.append(acc_score)\n",
    "\n",
    "    print(\"Average Loss: {}\".format(average_loss))\n",
    "    print(\"Acc Score: {}\".format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.forward(x_test)\n",
    "\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoding_predictions = one_hot_encoding(predictions.detach().cpu( ).numpy())\n",
    "\n",
    "one_hot_encoding_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, one_hot_encoding_predictions)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses, label='loss', color='red')\n",
    "plt.plot(accuracies, label='accuracy', color='blue')\n",
    "plt.title('Training Evaluation', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Magnitude', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
